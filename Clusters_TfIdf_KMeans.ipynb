{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Clusters_TfIdf_KMeans",
      "provenance": [],
      "authorship_tag": "ABX9TyOtroHa5K0FCBZlAk8ZKYDz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EduardoMoraesRitter/Introducao-NLP-clusterizacao/blob/master/Clusters_TfIdf_KMeans.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcqYKwWU0HOY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "aa6eb0ea-4cc2-40bd-d577-5147f6674c05"
      },
      "source": [
        "import string\n",
        "import collections\n",
        "import numpy as np\n",
        " \n",
        "import nltk\n",
        "nltk.download('rslp')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from pprint import pprint"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]   Package rslp is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxNbaAzf6Pwf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "73d8d258-ffe9-410b-eab1-cdae7741182e"
      },
      "source": [
        "#lista de caracteres\n",
        "string.punctuation"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqkCY_aA4_6s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aff26f64-869f-4ce0-db61-e274c4e36be3"
      },
      "source": [
        "#remover pontuacao\n",
        "\"parabéns pela, vitória cruzeiro essa!\".translate(str.maketrans('','',string.punctuation)) #text.translate(None, string.punctuation)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'parabéns pela vitória cruzeiro essa'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbH78HU758fv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9d143aa1-fc79-4f94-ce26-d212b44935d4"
      },
      "source": [
        "#separa palavras e pontuacao\n",
        "word_tokenize(\"parabéns pela, vitória cruzeiro essa!\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['parabéns', 'pela', ',', 'vitória', 'cruzeiro', 'essa', '!']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSy5KQUX60Z6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "00b52be3-5c13-41cc-be6f-373a009dbcfd"
      },
      "source": [
        "#raiz da palavra para o ingles\n",
        "from nltk.stem import PorterStemmer\n",
        "print(nltk.PorterStemmer().stem(\"running\"))\n",
        "#raiz da palavra para o portugues\n",
        "print(nltk.RSLPStemmer().stem(\"Parabéns\"))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "run\n",
            "parabém\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kc0Cj2Bz0kJb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e5fc84af-4baf-4f22-b3ad-70940e35ec7b"
      },
      "source": [
        "#remover a punctuation, cotar textos tokenize, raiz da palavra\n",
        "def process_text(text):\n",
        "    text = text.translate(str.maketrans('','',string.punctuation)) #text.translate(None, string.punctuation)\n",
        "    tokens = word_tokenize(text)\n",
        "    stemmer = nltk.RSLPStemmer()#PorterStemmer()\n",
        "    tokens = [stemmer.stem(t) for t in tokens]\n",
        "    return tokens\n",
        "  \n",
        "process_text('parabéns pela vitória cruzeiro essa!')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['parabém', 'pel', 'vitór', 'cruz', 'ess']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UP0RiQsdG79R",
        "colab_type": "text"
      },
      "source": [
        "FIM DO PRIMEIRO PASSO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQDQpdhWHAdl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "9ce2cc46-4e85-4aac-e5db-7779ebfb8bbd"
      },
      "source": [
        "print(stopwords.words('portuguese'))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['de', 'a', 'o', 'que', 'e', 'é', 'do', 'da', 'em', 'um', 'para', 'com', 'não', 'uma', 'os', 'no', 'se', 'na', 'por', 'mais', 'as', 'dos', 'como', 'mas', 'ao', 'ele', 'das', 'à', 'seu', 'sua', 'ou', 'quando', 'muito', 'nos', 'já', 'eu', 'também', 'só', 'pelo', 'pela', 'até', 'isso', 'ela', 'entre', 'depois', 'sem', 'mesmo', 'aos', 'seus', 'quem', 'nas', 'me', 'esse', 'eles', 'você', 'essa', 'num', 'nem', 'suas', 'meu', 'às', 'minha', 'numa', 'pelos', 'elas', 'qual', 'nós', 'lhe', 'deles', 'essas', 'esses', 'pelas', 'este', 'dele', 'tu', 'te', 'vocês', 'vos', 'lhes', 'meus', 'minhas', 'teu', 'tua', 'teus', 'tuas', 'nosso', 'nossa', 'nossos', 'nossas', 'dela', 'delas', 'esta', 'estes', 'estas', 'aquele', 'aquela', 'aqueles', 'aquelas', 'isto', 'aquilo', 'estou', 'está', 'estamos', 'estão', 'estive', 'esteve', 'estivemos', 'estiveram', 'estava', 'estávamos', 'estavam', 'estivera', 'estivéramos', 'esteja', 'estejamos', 'estejam', 'estivesse', 'estivéssemos', 'estivessem', 'estiver', 'estivermos', 'estiverem', 'hei', 'há', 'havemos', 'hão', 'houve', 'houvemos', 'houveram', 'houvera', 'houvéramos', 'haja', 'hajamos', 'hajam', 'houvesse', 'houvéssemos', 'houvessem', 'houver', 'houvermos', 'houverem', 'houverei', 'houverá', 'houveremos', 'houverão', 'houveria', 'houveríamos', 'houveriam', 'sou', 'somos', 'são', 'era', 'éramos', 'eram', 'fui', 'foi', 'fomos', 'foram', 'fora', 'fôramos', 'seja', 'sejamos', 'sejam', 'fosse', 'fôssemos', 'fossem', 'for', 'formos', 'forem', 'serei', 'será', 'seremos', 'serão', 'seria', 'seríamos', 'seriam', 'tenho', 'tem', 'temos', 'tém', 'tinha', 'tínhamos', 'tinham', 'tive', 'teve', 'tivemos', 'tiveram', 'tivera', 'tivéramos', 'tenha', 'tenhamos', 'tenham', 'tivesse', 'tivéssemos', 'tivessem', 'tiver', 'tivermos', 'tiverem', 'terei', 'terá', 'teremos', 'terão', 'teria', 'teríamos', 'teriam']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5McbwK27-wty",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "e6baff16-9ce7-420c-ee7a-cd7b81ab7f38"
      },
      "source": [
        "#usa o token nao remove o stopwords\n",
        "vectorizer1 = TfidfVectorizer(tokenizer=process_text)\n",
        "X = vectorizer1.fit_transform(['Parabéns pela vitória cruzeiro essa!', 'cruzeiro jogou minha otimo!'])\n",
        "print(X.shape)\n",
        "print(vectorizer1.get_feature_names())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2, 8)\n",
            "['cruz', 'ess', 'jog', 'minh', 'otim', 'parabém', 'pel', 'vitór']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--z6HgOx8oS0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "f5595e40-31bd-45a8-dbb2-4f31e5cec0e8"
      },
      "source": [
        "#remove stopwords porem nao usa token\n",
        "vectorizer2 = TfidfVectorizer(stop_words=stopwords.words('portuguese'))\n",
        "teste = vectorizer2.fit_transform(['Parabéns pela vitória cruzeiro essa!', 'cruzeiro jogou minha otimo!'])\n",
        "print(teste.shape)\n",
        "print(vectorizer2.get_feature_names())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2, 5)\n",
            "['cruzeiro', 'jogou', 'otimo', 'parabéns', 'vitória']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8SidLK87_Qz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "4f65081d-0906-4319-9b76-6c09c42e390d"
      },
      "source": [
        "#usa o token e remove stopwords, porem com erro, pq o stopword nao estão em raiz e sim completo\n",
        "vectorizer3 = TfidfVectorizer(tokenizer=process_text, stop_words=stopwords.words('portuguese'))\n",
        "teste = vectorizer3.fit_transform(['Parabéns pela vitória cruzeiro essa!', 'cruzeiro jogou minha otimo!'])\n",
        "print(teste.shape)\n",
        "print(vectorizer3.get_feature_names())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2, 8)\n",
            "['cruz', 'ess', 'jog', 'minh', 'otim', 'parabém', 'pel', 'vitór']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aquel', 'aquil', 'del', 'entr', 'er', 'ess', 'est', 'estej', 'estev', 'estiv', 'estivér', 'estivéss', 'fom', 'form', 'foss', 'fôr', 'fôss', 'haj', 'hav', 'houv', 'houvér', 'houvéss', 'iss', 'ist', 'mesm', 'minh', 'muit', 'noss', 'nó', 'par', 'pel', 'qu', 'sej', 'ser', 'som', 'tenh', 'ter', 'tev', 'tinh', 'tiv', 'tivér', 'tivéss', 'tính', 'vo', 'voc', 'ér'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ap3gkrSJk2fl",
        "colab_type": "text"
      },
      "source": [
        "por gerar muito erro o processo de limpasa pode ser feita a parte"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdmbmtB2k_CE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "f6a037b0-93d0-4729-984c-e5c994450fba"
      },
      "source": [
        "#coloca os stopword em raiz e remove os itens repetidos\n",
        "stopwords_stemmer_uniq = np.unique([nltk.RSLPStemmer().stem(t) for t in stopwords.words('portuguese')])\n",
        "print(stopwords_stemmer_uniq)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['a' 'ao' 'aquel' 'aquil' 'as' 'até' 'com' 'da' 'de' 'del' 'depois' 'do'\n",
            " 'e' 'ela' 'ele' 'em' 'entr' 'er' 'era' 'ess' 'est' 'estej' 'estev'\n",
            " 'estiv' 'estivér' 'estivéss' 'eu' 'foi' 'fom' 'for' 'form' 'foss' 'fui'\n",
            " 'fôr' 'fôss' 'haj' 'hav' 'hei' 'houv' 'houvér' 'houvéss' 'há' 'hão' 'iss'\n",
            " 'ist' 'já' 'lhe' 'mais' 'mas' 'me' 'mesm' 'meu' 'minh' 'muit' 'na' 'nem'\n",
            " 'no' 'noss' 'num' 'não' 'nó' 'o' 'os' 'ou' 'par' 'pel' 'por' 'qu' 'qual'\n",
            " 'que' 'se' 'sej' 'sem' 'ser' 'seu' 'som' 'sou' 'sua' 'são' 'só' 'também'\n",
            " 'te' 'tem' 'tenh' 'ter' 'teu' 'tev' 'tinh' 'tiv' 'tivér' 'tivéss' 'tu'\n",
            " 'tua' 'tém' 'tính' 'um' 'uma' 'vo' 'voc' 'à' 'às' 'é' 'ér']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpT0QOAqk_P3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "frases = ['o cruzeiro jogou muito bem', \n",
        "            'parabéns pela vitória cruzeiro!',\n",
        "            'ainda acho o cruzeiro ruim', \n",
        "            'o cruzeiro não jogou bem',\n",
        "            'cruzeiro jogou contra o sport',\n",
        "            'primeira rodada o cruzeiro enfrentou o sport',\n",
        "            'bela vitória do cruzeiro', \n",
        "            'mais uma vitória do cruzeiro']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EthRRo6k_M0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "dca78f7f-477f-4ad5-b131-3d01f0bbe98f"
      },
      "source": [
        "#pega as raiz das frases\n",
        "frases_raiz = [' '.join(process_text(frase)) for frase in frases]\n",
        "print(frases_raiz)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['o cruz jog muit bem', 'parabém pel vitór cruz', 'aind ach o cruz ruim', 'o cruz não jog bem', 'cruz jog contr o sport', 'prim rod o cruz enfrent o sport', 'bel vitór do cruz', 'mais uma vitór do cruz']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRMokcx9iJ8v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "7bb94ddb-59a4-4cea-fa3d-2fbec1f3ff7f"
      },
      "source": [
        "vectorizer4 = TfidfVectorizer()\n",
        "teste = vectorizer4.fit_transform(frases_raiz)\n",
        "print(teste.shape)\n",
        "print(vectorizer4.get_feature_names())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8, 20)\n",
            "['ach', 'aind', 'bel', 'bem', 'contr', 'cruz', 'do', 'enfrent', 'jog', 'mais', 'muit', 'não', 'parabém', 'pel', 'prim', 'rod', 'ruim', 'sport', 'uma', 'vitór']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjP_BvOXiJ_6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Transform texts to Tf-Idf coordinates and cluster texts using K-Means\n",
        "def cluster_texts(frases, clusters=3):\n",
        "\n",
        "    stopwords_stemmer_uniq = np.unique([nltk.RSLPStemmer().stem(t) for t in stopwords.words('portuguese')])\n",
        "    frases_raiz = [' '.join(process_text(frase)) for frase in frases]\n",
        "\n",
        "    Tfidf = TfidfVectorizer()\n",
        "    tfidf_model = Tfidf.fit_transform(frases_raiz)\n",
        "    km_model = KMeans(n_clusters=clusters)\n",
        "    km_model.fit(tfidf_model)\n",
        " \n",
        "    clustering = collections.defaultdict(list)\n",
        " \n",
        "    for idx, label in enumerate(km_model.labels_):\n",
        "        clustering[label].append(idx)\n",
        " \n",
        "    return clustering"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXN0sp0HnG3E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9c930309-1f0b-4bf4-ef50-dca9da30d44e"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    articles = ['o cruzeiro jogou muito bem', \n",
        "            'parabéns pela vitória cruzeiro!',\n",
        "            'ainda acho o cruzeiro ruim', \n",
        "            'o cruzeiro não jogou bem',\n",
        "            'cruzeiro jogou contra o sport',\n",
        "            'primeira rodada o cruzeiro enfrentou o sport',\n",
        "            'bela vitória do cruzeiro', \n",
        "            'mais uma vitória do cruzeiro']\n",
        "    clusters = cluster_texts(articles, 3)\n",
        "    pprint(dict(clusters))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: [2, 4, 5], 1: [1, 6, 7], 2: [0, 3]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhuG6Vw_E_QZ",
        "colab_type": "text"
      },
      "source": [
        "FIM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRnJBJA3Tiew",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "50a114be-9d64-4b7b-bc23-e7b789aa88c9"
      },
      "source": [
        "#Na x<5verdade, esse não é um valor booleano, mas uma matriz de 10 bools, indicando quais valores estão abaixo de 5.\n",
        "x = np.arange(10)\n",
        "print(x)\n",
        "if x<5: print('!')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 2 3 4 5 6 7 8 9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-e0258b78f33c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#como fazer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrTFLOjxo9t4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "02114340-afbf-4966-b0d5-c0dd14e9fe88"
      },
      "source": [
        "#como fazer\n",
        "if (np.arange(10)<5).any(): print('!')\n",
        "#if (np.arange(10)<5).all(): print('!')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}